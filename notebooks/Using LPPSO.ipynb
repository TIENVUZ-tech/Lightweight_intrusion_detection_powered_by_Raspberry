{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4cea88bc",
      "metadata": {
        "id": "4cea88bc"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "70e462fe",
      "metadata": {
        "id": "70e462fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8a28fb4-9093-42b7-89ff-2b6821e48d0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyswarms\n",
            "  Downloading pyswarms-1.3.0-py2.py3-none-any.whl.metadata (33 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pyswarms) (1.16.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pyswarms) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from pyswarms) (3.10.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.12/dist-packages (from pyswarms) (25.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from pyswarms) (4.67.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from pyswarms) (1.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from pyswarms) (6.0.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=1.3.1->pyswarms) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=1.3.1->pyswarms) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=1.3.1->pyswarms) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=1.3.1->pyswarms) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=1.3.1->pyswarms) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=1.3.1->pyswarms) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=1.3.1->pyswarms) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=1.3.1->pyswarms) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=1.3.1->pyswarms) (1.17.0)\n",
            "Downloading pyswarms-1.3.0-py2.py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyswarms\n",
            "Successfully installed pyswarms-1.3.0\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "!pip install pyswarms\n",
        "\n",
        "import glob\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pyswarms as ps\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE # Dùng để cân bằng dữ liệu\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, BatchNormalization, Conv1D, MaxPooling1D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Kết nối Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# CẤU HÌNH ĐƯỜNG DẪN\n",
        "# Hãy thay đổi đường dẫn này trỏ đến thư mục chứa dataset của bạn trên Drive\n",
        "DATASET_PATH = \"/content/drive/My Drive/Colab Notebooks/Model_on_pi/data/raw/CSE-CIC-IDS2018\"\n",
        "SAMPLE_PER_FILE = 50000 # Lấy 50.000 mẫu mỗi file để xử lý"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44323775",
      "metadata": {
        "id": "44323775"
      },
      "source": [
        "# Load And Clean Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f15c85c",
      "metadata": {
        "id": "5f15c85c",
        "outputId": "84f1611e-f21c-44b1-da04-d501e41867cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đã xử lý: DoS attacks-Slowloris.csv | Shape: (36754, 71)\n",
            "Đã xử lý: DDOS attack-LOIC-UDP.csv | Shape: (5784, 71)\n",
            "Đã xử lý: Brute Force -XSS.csv | Shape: (734, 71)\n",
            "Đã xử lý: SQL Injection.csv | Shape: (286, 71)\n",
            "Đã xử lý: Brute Force -Web.csv | Shape: (2073, 71)\n",
            "Đã xử lý: DoS attacks-GoldenEye.csv | Shape: (50000, 71)\n",
            "Đã xử lý: DoS attacks-SlowHTTPTest.csv | Shape: (50000, 71)\n",
            "Đã xử lý: Bot.csv | Shape: (50000, 71)\n",
            "Đã xử lý: DDOS attack-HOIC.csv | Shape: (50000, 71)\n",
            "Đã xử lý: Infilteration.csv | Shape: (50000, 71)\n"
          ]
        }
      ],
      "source": [
        "def load_and_clean_data(folder_path, sample_size):\n",
        "    all_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
        "\n",
        "    processed_frames = []\n",
        "\n",
        "    # Loại bỏ một vài code không cần thiết trước khi chạy LKPSO\n",
        "    cols_to_drop = [\n",
        "        'Flow ID', 'Source IP', 'Source Port', 'Destination IP', 'Destination Port', 'Timestamp',\n",
        "        'Bwd PSH Flags', 'Bwd URG Flags', 'Fwd URG Flags', 'CWE Flag Count',\n",
        "        'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate',\n",
        "        'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate',\n",
        "        'Subflow Fwd Pkts', 'Subflow Fwd Byts', 'Subflow Bwd Pkts', 'Subflow Bwd Byts',\n",
        "        'Fwd Header Length.1'\n",
        "    ]\n",
        "\n",
        "    for file in all_files:\n",
        "        try:\n",
        "            # Đọc file với tùy chọn low_memory=False để tránh cảnh báo\n",
        "            df = pd.read_csv(file, low_memory=False)\n",
        "            df.columns = df.columns.str.strip() # Xóa khoảng trắng tên cột\n",
        "\n",
        "            # Lấy mẫu ngẫu nhiên nếu file quá lớn\n",
        "            if len(df) > sample_size:\n",
        "                df_sampled = df.sample(n=sample_size, random_state=42)\n",
        "            else:\n",
        "                df_sampled = df\n",
        "\n",
        "            # Xóa các cột không quan trọng khi nó tồn tại trong bộ dữ liệu\n",
        "            existing_cols = [c for c in cols_to_drop if c in df_sampled.columns]\n",
        "            df_sampled = df_sampled.drop(columns=existing_cols)\n",
        "\n",
        "            # Xử lý NaN/Inf (Thay thế vô cực bằng NaN rồi xóa dòng NaN)\n",
        "            df_sampled = df_sampled.replace([np.inf, -np.inf], np.nan).dropna()\n",
        "\n",
        "            processed_frames.append(df_sampled)\n",
        "            print(f\"Đã xử lý: {os.path.basename(file)} | Shape: {df_sampled.shape}\")\n",
        "\n",
        "            del df # Giải phóng RAM\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Lỗi đọc file {file}: {e}\")\n",
        "\n",
        "    # Gộp tất cả dữ liệu lại\n",
        "    if processed_frames:\n",
        "        print(\"Đang ghép nối dữ liệu...\")\n",
        "        combined_df = pd.concat(processed_frames, ignore_index=True)\n",
        "        print(f\"Tổng kích thước dữ liệu sau gộp: {combined_df.shape}\")\n",
        "        return combined_df\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Gọi hàm tải dữ liệu\n",
        "df = load_and_clean_data(DATASET_PATH, SAMPLE_PER_FILE)\n",
        "\n",
        "# Kiểm tra và tách X, y\n",
        "if df is not None and 'Label' in df.columns:\n",
        "    X = df.drop('Label', axis=1)\n",
        "    y = df['Label']\n",
        "\n",
        "    # Mã hóa nhãn (Label Encoding)\n",
        "    le = LabelEncoder()\n",
        "    y_encoded = le.fit_transform(y)\n",
        "    num_classes = len(le.classes_)\n",
        "    print(\"Các lớp tấn công tìm thấy:\", le.classes_)\n",
        "else:\n",
        "    print(\"Lỗi dữ liệu hoặc không tìm thấy cột Label\")\n",
        "    exit()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Likely Point PSO to choose the most important features"
      ],
      "metadata": {
        "id": "jat4JZIMOZQ6"
      },
      "id": "jat4JZIMOZQ6"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Đang chạy Feature Selection với LPPSO\")\n",
        "\n",
        "# Lấy một mẫu nhỏ để chạy PSO cho nhanh\n",
        "X_pso, _, y_pso, _ = train_test_split(X, y_encoded, train_size=20000, stratify=y_encoded, random_state=42)\n",
        "\n",
        "# Hàm Fitness cho PSO (Mục tiêu: Tăng Accuracy, Giảm số lượng Feature)\n",
        "def f_per_particle(m, alpha=0.9):\n",
        "    if np.count_nonzero(m) == 0:\n",
        "        return 1.0 # Phạt nếu không chọn feature nào\n",
        "\n",
        "    # Chỉ lấy các cột được chọn (m[i] == 1)\n",
        "    X_subset = X_pso.iloc[:, m == 1]\n",
        "\n",
        "    # Dùng RandomForest nhẹ để đánh giá độ hiệu quả của tập feature này\n",
        "    clf = RandomForestClassifier(n_estimators=20, n_jobs=-1, random_state=42)\n",
        "    clf.fit(X_subset, y_pso)\n",
        "    acc = clf.score(X_subset, y_pso)\n",
        "\n",
        "    # Hàm mục tiêu (Cost function) cần giảm thiểu\n",
        "    n_features = X_subset.shape[1]\n",
        "    total_features = X_pso.shape[1]\n",
        "    j = (alpha * (1.0 - acc)) + ((1.0 - alpha) * (n_features / total_features))\n",
        "    return j\n",
        "\n",
        "def f(x):\n",
        "    n_particles = x.shape[0]\n",
        "    j = [f_per_particle(x[i] > 0.5) for i in range(n_particles)]\n",
        "    return np.array(j)\n",
        "\n",
        "# Cấu hình PSO\n",
        "options = {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n",
        "dimensions = X.shape[1]\n",
        "optimizer = ps.discrete.BinaryPSO(n_particles=15, dimensions=dimensions, options=options)\n",
        "\n",
        "# Chạy tối ưu hóa\n",
        "cost, pos = optimizer.optimize(f, iters=15)\n",
        "\n",
        "# Lấy danh sách đặc trưng đã chọn\n",
        "selected_indices = np.where(pos == 1)[0]\n",
        "SELECTED_FEATURES = X.columns[selected_indices].tolist()\n",
        "\n",
        "print(f\"Đã chọn được {len(SELECTED_FEATURES)} đặc trưng quan trọng nhất:\")\n",
        "print(SELECTED_FEATURES)"
      ],
      "metadata": {
        "id": "h4SrmSQuOhBK"
      },
      "id": "h4SrmSQuOhBK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f93f4d2e",
      "metadata": {
        "id": "f93f4d2e"
      },
      "source": [
        "# Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b713a8df",
      "metadata": {
        "id": "b713a8df"
      },
      "outputs": [],
      "source": [
        "print(\"Chuẩn bị dữ liệu huấn luyện\")\n",
        "\n",
        "# Chỉ giữ lại các đặc trưng PSO đã chọn\n",
        "X_final = X[SELECTED_FEATURES]\n",
        "\n",
        "# Cân bằng dữ liệu bằng SMOTE (Optional nhưng tốt cho các lớp thiểu số)\n",
        "try:\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_resampled, y_resampled = smote.fit_resample(X_final, y_encoded)\n",
        "except Exception as e:\n",
        "    print(f\"{e}\")\n",
        "    X_resampled, y_resampled = X_final, y_encoded\n",
        "\n",
        "# Chia tập Train/Test (80/20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled\n",
        ")\n",
        "\n",
        "# Chuẩn hóa Min-Max\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Lưu scaler để dùng sau này trên Raspberry Pi\n",
        "joblib.dump(scaler, 'scaler.pkl')\n",
        "\n",
        "# Reshape cho mô hình (Samples, Timesteps=1, Features)\n",
        "# CNN-LSTM cần đầu vào 3 chiều\n",
        "X_train_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], 1, X_train_scaled.shape[1])\n",
        "X_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], 1, X_test_scaled.shape[1])\n",
        "\n",
        "# One-hot encoding cho label\n",
        "y_train_onehot = to_categorical(y_train)\n",
        "y_test_onehot = to_categorical(y_test)\n",
        "\n",
        "print(f\"Input Shape cho mô hình: {X_train_reshaped.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "340c2f2c",
      "metadata": {
        "id": "340c2f2c"
      },
      "source": [
        "# Create hybrid model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1aef427b",
      "metadata": {
        "id": "1aef427b"
      },
      "outputs": [],
      "source": [
        "def create_hybrid_model(input_shape, num_classes):\n",
        "    model = Sequential()\n",
        "\n",
        "    # 1D_CNN (Trích xuất đặc trưng không gian)\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling1D(pool_size=1))\n",
        "\n",
        "    # LSTM (Học phụ thuộc thời gian)\n",
        "    model.add(LSTM(units=128, return_sequences=False))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # Output (Phân loại)\n",
        "    model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Tạo mô hình\n",
        "input_shape = (X_train_reshaped.shape[1], X_train_reshaped.shape[2])\n",
        "model = create_hybrid_model(input_shape, num_classes)\n",
        "model.summary()\n",
        "\n",
        "# Thiết lập callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "model_checkpoint = ModelCheckpoint('model_hybrid_pso.keras', monitor='val_accuracy', save_best_only=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af78166a",
      "metadata": {
        "id": "af78166a"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3789f4e5",
      "metadata": {
        "id": "3789f4e5"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    X_train_reshaped, y_train_onehot,\n",
        "    epochs=15,\n",
        "    batch_size=70,\n",
        "    validation_data=(X_test_reshaped, y_test_onehot),\n",
        "    callbacks=[early_stopping, model_checkpoint],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Đánh giá\n",
        "print(\"Đánh giá mô hình trên tập Test...\")\n",
        "evaluation = model.evaluate(X_test_reshaped, y_test_onehot, verbose=0)\n",
        "print(f\"Test Loss: {evaluation[0]:.4f}\")\n",
        "print(f\"Test Accuracy: {evaluation[1] * 100:.2f}%\")\n",
        "\n",
        "# Vẽ biểu đồ\n",
        "plt.figure(figsize=(12,4))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.history['accuracy'], label=\"Training Accuracy\")\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history['loss'], label=\"Training Loss\")\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title(\"Model Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65bcb4c9",
      "metadata": {
        "id": "65bcb4c9"
      },
      "outputs": [],
      "source": [
        "def Main():\n",
        "    print(\"Traning completed!\")\n",
        "\n",
        "Main()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}